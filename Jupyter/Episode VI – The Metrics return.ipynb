{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Wars\n",
    "## ~ Episode VI – The Metrics return ~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we should set the notebook so that it outputs all results of each cell and not only the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And import all the python libraries needed for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import neighbors\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we state where our data sources are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = 'data\\\\'\n",
    "\n",
    "predictions_file_path = data_folder_path + 'predictions.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(predictions_file_path, sep = ';', index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to start with the performance analysis process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "This are some of the most common metrics which fit the recomendation problem when it is treated as a regression on a rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply averages the absolute error of the difference between the actual and predicted ratings. For a test dataset of *n* samples is defined as:\n",
    "\n",
    "\\\\[MAE =  (\\frac{1}{n})\\sum_{i=1}^{n}\\left | rating_{i} - predicted_{i} \\right | \\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(pred, actual):\n",
    "    error_function = lambda x, y : abs(x - y)\n",
    "    \n",
    "    errors = map(error_function, preds, actuals)\n",
    "    \n",
    "    return sum(errors)/len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean absolute error can not only be used to compare different models. Even when we have a single model it has meaning in itself, it tell us information about the **expected error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the average of the squared differences between the actual and predicted ratings. For a test dataset of *n* samples is defined as:\n",
    "\n",
    "\\\\[MSE =  (\\frac{1}{n})\\sum_{i=1}^{n}\\left ( rating_{i} - predicted_{i} \\right )^{2} \\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(pred, actual):\n",
    "    error_function = lambda x, y : math.sqrt(x, y)\n",
    "    \n",
    "    errors = map(error_function, preds, actuals)\n",
    "    \n",
    "    return sum(errors)/len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to penalize the higher differences between the real ratings and the predicted ones, the the mean squared error is a  very common solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Frequency Penalized Squared Error (MFPSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heavely penalizes prediction errors between frequent rates but errors between rare rates are keep the same. For a test dataset of *n* samples is defined as:\n",
    "\n",
    "\\\\[MFPSE = (\\frac{1}{n})\\sum_{i=1}^{n}\\left | rating_{i} - predicted_{i} \\right | ( 1 + \\lambda f_{i}) \\\\]\n",
    "\n",
    "where:\n",
    "\n",
    "\\\\[ f_i = \\frac{\\text{Number of ratings with value equal to } rating_{i}}{\\text{Total number of ratings}} \\\\]\n",
    "\n",
    "We have to adjust the  $\\lambda$ parameter to control the effect of the frequency coefficient, $\\lambda = \\frac{1}{2}$ is a good start point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFPSE(preds, actuals, penalty = 1):\n",
    "    ratings = (1,2,3,4,5)\n",
    "    normal_distances = map(lambda x : Counter(actuals[x])/len(actuals), ratings)\n",
    "    penalites = map(lambda x: penalty * normal_distances[x], actuals)\n",
    "    \n",
    "    error_function = lambda x, y, p : math.sqrt(x - y) * (1 + p)\n",
    "    errors = map(error_function, preds, actuals, penalties)\n",
    "    \n",
    "    return sum(errors)/len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean frequency penalized squared error is useful when the data points are very concentrated around a given value, **3.6** in our case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Asymmetry Penalized Squared Error (MAPSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes in consideration the non-symmetric character of errors. For a testset of *n* samples is defined as:\n",
    "\n",
    "\\\\[MAPSE = (\\frac{1}{n})\\sum_{i=1}^{n}\\left | rating_{i} - predicted_{i} \\right | (1 + p(rating_i, predicted_i) \\\\]\n",
    "\n",
    "where:\n",
    "\n",
    "\\\\[ p(x, y) = \\lambda \\frac{(x-y)|x-y|}{16} \\lambda \\in [0,1] \\\\]\n",
    "\n",
    "\n",
    "We have to adjust the  $\\lambda$ parameter to control the effect of the assymetry coefficient, $\\lambda = \\frac{1}{5}$ is a good start point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPSE(preds, actuals, penalty = 0.75):\n",
    "    penalites = map(lambda x, y : penalty * 1/16 * (x - y) * abs(x - y), preds, actuals)\n",
    "    \n",
    "    error_function = lambda x, y, p : math.sqrt(x - y) * (1 + p)\n",
    "    errors = map(error_function, preds, actuals, penalties)\n",
    "    \n",
    "    return sum(errors)/len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now if the recommender predicts a rating for a concrete movie and user (let's say 5) and the user's real rating is 1, the error is the same if the recommender predicts a rating of 1 and the user's real rating is 5.\n",
    "\n",
    "These symmetries are not realistic because in fact if you give a try to a movie which seems awful and finally you can enjoy it the \"damage\" is lower than if the system recommend you a film and after watch it you are dissapointed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison\n",
    "\n",
    "To sum up we resume the principal features of the metrics in the following table.\n",
    "\n",
    "| Metric | Meaningful | Penalizes higher errors | Distribution-aware | Letdown-aware |\n",
    "|--------|------------|-------------------------|--------------------|---------------|\n",
    "| MAE    | ✓          | ✗                      | ✗                  | ✗             |\n",
    "| MSE    | ✗          | ✓                      | ✗                  | ✗             |\n",
    "| MFPSE  | ✗          | ✓                      | ✓                  | ✗             |\n",
    "| MAPSE  | ✗          | ✓                      | ✗                  | ✓             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets calculate the MAE, MSE, MFPSE and MAPSE of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Naïve', \n",
    "        'K-Nearest Neighbors', \n",
    "        'Random Forest', \n",
    "        'Artificial Neural Networks', \n",
    "        'Matrix Factorization'\n",
    "    ],\n",
    "    \n",
    "     'MAE': [\n",
    "         MAE(predictions['naive_pred'], predictions['actual']),\n",
    "         MAE(predictions['knn_pred'], predictions['actual']),\n",
    "         MAE(predictions['rf_pred'], predictions['actual']),\n",
    "         MAE(predictions['nn_pred'], predictions['actual']),\n",
    "         MAE(predictions['mf_pred'], predictions['actual'])\n",
    "     ],\n",
    "     \n",
    "     'MSE': [\n",
    "         MSE(predictions['naive_pred'], predictions['actual']),\n",
    "         MSE(predictions['knn_pred'], predictions['actual']),\n",
    "         MSE(predictions['rf_pred'], predictions['actual']),\n",
    "         MSE(predictions['nn_pred'], predictions['actual']),\n",
    "         MSE(predictions['mf_pred'], predictions['actual'])\n",
    "     ], \n",
    "     \n",
    "     'MFPSE': [\n",
    "         MFPSE(predictions['naive_pred'], predictions['actual']),\n",
    "         MFPSE(predictions['knn_pred'], predictions['actual']),\n",
    "         MFPSE(predictions['rf_pred'], predictions['actual']),\n",
    "         MFPSE(predictions['nn_pred'], predictions['actual']),\n",
    "         MFPSE(predictions['mf_pred'], predictions['actual'])\n",
    "     ], \n",
    "     \n",
    "     'MAPSE':[\n",
    "         MAPSE(predictions['naive_pred'], predictions['actual']),\n",
    "         MAPSE(predictions['knn_pred'], predictions['actual']),\n",
    "         MAPSE(predictions['rf_pred'], predictions['actual']),\n",
    "         MAPSE(predictions['nn_pred'], predictions['actual']),\n",
    "         MAPSE(predictions['mf_pred'], predictions['actual'])\n",
    "     ] \n",
    "    })\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how the models behave, we use the density of the **absolute error values** to **estimate their distribution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_error_density = pd.DataFrame({\n",
    "        'Error': np.linspace(0,4,1000),\n",
    "        'Naïve': gaussian_kde(ratings_test_data['Naive_abs_error']).evaluate(ind),\n",
    "        'K-Nearest Neighbors': gaussian_kde(ratings_test_data['Naive_abs_error']).evaluate(ind),\n",
    "        'Random Forest': gaussian_kde(ratings_test_data['Naive_abs_error']).evaluate(ind),\n",
    "        'Artificial Neural Network': gaussian_kde(ratings_test_data['Naive_abs_error']).evaluate(ind),\n",
    "        'Matrix Factorization': gaussian_kde(ratings_test_data['Naive_abs_error']).evaluate(ind)\n",
    "    })\n",
    "\n",
    "plt.title('Density of absolute error')\n",
    "plt.xlabel('Absolute error')\n",
    "plt.ylabel('Density')\n",
    "plt.plot(absolute_error_density['Error'], absolute_error_density['Naïve'], label = \"Naïve\")\n",
    "plt.plot(absolute_error_density['Error'], absolute_error_density['K-Nearest Neighbors'], label = \"K-Nearest Neighbors\")\n",
    "plt.plot(absolute_error_density['Error'], absolute_error_density['Random Forest'], label = \"Random Forest\")\n",
    "plt.plot(absolute_error_density['Error'], absolute_error_density['Artificial Neural Network'], label = \"Artificial Neural Network\")\n",
    "plt.plot(absolute_error_density['Error'], absolute_error_density['Matrix Factorization'], label = \"Matrix Factorization\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to observe that due to the heavely centered distribution of the ratings the naïve approximation is not bad at all with a **MAE** less than 1 and the ratings being integers, implies that **we don't have much room for improvement**. \n",
    "\n",
    "The profile-based models(**KNN, Random Forest and Artificial Neural Networks**) show a better behavior than the naive approach, but the improvement **is not very significant**, which is to be expected since the movie likes and dislikes is a complex and personal thing.\n",
    "\n",
    "The only model that stands out is the one based on **Matrix Factorization** as we already expected, since as an user-user collaborative filtering method it was specially created to handle this kind of scenarios. \n",
    "\n",
    "In the density plots of the absolute error we see a similar situation, but we distinguish between models with good generalization such as Matrix Factorization and KNN, and those that doesn't such as Naïve, Random Forest and Artificial Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "In order to stablish a starting model, we have tried prototypes from the models shown previously (and additional ones) for this problem and tabulate the results.\n",
    "\n",
    "| Metrics | Naïve (mean)| Neural Netwoks | KNN | Decision Tree | Random Forest | Gradient-boost |  ADA-boost | Matrix factorization |\n",
    "|---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| Accuracy training (MAE)  | 0.93 |0.91  | 0.8  |  0.78 | 0.78  | 0.79  | 0.9  | 0.49 |\n",
    "| Accuracy testing (MAE) | 0.93 |  0.91 |  0.82 | 0.81  | 0.8  | 0.79  | 0.9  | 0.68 |\n",
    "| Training time (500k)| 0'' | 4'' | 7'  | 1' | 12'  | 1'' |  1'' | 1''  |\n",
    "| Training time (26M) | 0'' |  10'' |  1h | 10'  | 2h  | 12h  | 15h | 1' ~ 5' |\n",
    "| Support new users/movies  | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✗ |\n",
    "| Support additional information| ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✗ |\n",
    "| Programming language | Any language | Python | Python | Python | Python | Python | Python | C# |\n",
    "| Machine Learning library |-| sklearn | sklearn | sklearn | sklearn | sklearn | sklearn | ML.NET |\n",
    "| Model size (500k) | 0kB | 200kB  |  32Mb | 345kB  |  7Mb | 390kB | 10Mb  | 3Mb |\n",
    "| Model size (26M) | 0kB | 200kB  |  16Gb |  1Mb |  10Mb |  10Mb| 10Mb  | 120Mb |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factors to consider from the **data scientist** point of view:\n",
    "\n",
    "- The distribution of our target feature is very centered so dull models are capable of give us an acceptable performance but it's hard to improve it significantly\n",
    "- What level of accuracy is good enough?\n",
    "- We don't have the additional information available for all the users of the company, will the model still work without it.\n",
    "- Is the model explainable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**machine learning engineer**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In conclusion, based in this results, we choose to further develop our movie recommender system based on the Matrix Factorization model and implemented in ML.Net**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
