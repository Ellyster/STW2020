{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Wars\n",
    "## ~ BONUS â€“ The dark side of The Data ~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we should set the notebook so that it outputs all results of each cell and not only the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And import all the python libraries needed for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import neighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define how to plot a **confusion matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred,classes, normalize = False, title = None, cmap = plt.cm.Blues, size = 4):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Only use the labels that appear in the data\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    ax.figure.colorbar(im, ax = ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks = np.arange(cm.shape[1]),\n",
    "           yticks = np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels = classes, yticklabels = classes,\n",
    "           title = title,\n",
    "           ylabel = 'True label',\n",
    "           xlabel = 'Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation = 45, ha = \"right\",\n",
    "             rotation_mode = \"anchor\")\n",
    "    \n",
    "    fig.set_size_inches(size, size)\n",
    "    \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha = \"center\", va = \"center\",\n",
    "                    color = \"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we state where our data sources are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = 'data\\\\'\n",
    "\n",
    "user_profiles_file_path = data_folder_path + 'user_profiles.csv'\n",
    "movie_profiles_file_path = data_folder_path + 'movie_profiles.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profiles = pd.read_csv(user_profiles_file_path, sep = ';')\n",
    "movie_profiles = pd.read_csv(movie_profiles_file_path, sep = ';')\n",
    "\n",
    "movie_genres = ['Action','Adventure','Animation',\"Children's\",'Comedy','Crime','Documentary','Drama',\n",
    "                'Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi','Thriller','War','Western']\n",
    "\n",
    "user_occupations = { 0:  \"other\", 1:  \"academic/educator\", 2:  \"artist\",  3:  \"clerical/admin\", 4:  \"college/grad student\",\n",
    "                    5:  \"customer service\", 6:  \"doctor/health care\", 7:  \"executive/managerial\", 8:  \"farmer\", 9:  \"homemaker\",\n",
    "                     10:  \"K-12 student\", 11:  \"lawyer\", 12:  \"programmer\", 13:  \"retired\", 14:  \"sales/marketing\", 15:  \"scientist\",\n",
    "                     16:  \"self-employed\", 17:  \"technician/engineer\", 18:  \"tradesman/craftsman\", 19:  \"unemployed\", 20:  \"writer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some normalizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profiles['Favorite_epoch_norm'] = (user_profiles['Favorite epoch']-user_profiles['Favorite epoch'].min())/(user_profiles['Favorite epoch'].max() - user_profiles['Favorite epoch'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And split our data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train, users_test = train_test_split(user_profiles, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to start diggin on the dark side of The Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User's gender prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we list the features for training the model. In this case we use the favorite movie genres associated with each user to predict their gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_training = [x + '_affinity' for x in movie_genres]\n",
    "target_feature = 'Gender'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As preprocessing step, we perform random oversampling over the user gender to balance the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = users_train[features_for_training]\n",
    "x_test = users_test[features_for_training]\n",
    "y_train = users_train[target_feature]\n",
    "y_test = users_test[target_feature]\n",
    "\n",
    "ros = RandomOverSampler(random_state = 0, sampling_strategy = 0.75)\n",
    "x_train_resampled, y_train_resampled = ros.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we use simple LogisticRegression for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(random_state = 0, max_iter = 100)\n",
    "LR.fit(x_train_resampled, y_train_resampled);\n",
    "\n",
    "print('Test_score', round(LR.score( x_test, y_test), 2), 'Train_score', round(LR.score( x_train, y_train), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a good initial predictor for user gender, we can highlight the umbalance towards male gender as the principal problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR.predict(x_test)\n",
    "plot_confusion_matrix(y_test, y_pred, classes = ['Male', 'Female'],  normalize = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User's age prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to predict user's age. We use features related to the favorite movies genre again. In this case we will train a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_training = [x + '_affinity' for x in movie_genres]\n",
    "target_feature = 'Age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = users_train[features_for_training]\n",
    "x_test = users_test[features_for_training]\n",
    "y_train = users_train[target_feature] \n",
    "y_test = users_test[target_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a decomposition in principal components over the training data to reduce the noise and the dimensionality of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 16)\n",
    "\n",
    "pca.fit(x_train)\n",
    "\n",
    "x_train_pca = pd.DataFrame(pca.transform(x_train))\n",
    "x_test_pca = pd.DataFrame(pca.transform(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After it we use a gradient boost based regressor for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = GradientBoostingRegressor(random_state = 1, n_estimators = 1500)\n",
    "GB.fit(x_train_pca, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model we measure how good is it and we obtain an acceptable error, but in contrast there is a remarkable difference between test and training error which is indicative of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = GB.predict(x_train_pca) \n",
    "pred_test = GB.predict(x_test_pca)\n",
    "\n",
    "Ages_list = [1,18,25,35,45,50,56]\n",
    "pred_test = [min(Ages_list, key = lambda x: abs(x - y)) for y in pred_test]\n",
    "\n",
    "print('MAE(TRAINING): ', round(mean_absolute_error(pred_train ,y_train),2))\n",
    "print('MAE(TEST): ', round(mean_absolute_error(pred_test , y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User's occupation prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extend our later training data including personal information of the users to predict the occupation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_training = [x + '_affinity' for x in movie_genres] + ['Age', 'Gender', 'Favorite epoch']\n",
    "target_feature = 'Occupation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = users_train[features_for_training] \n",
    "x_test = users_test[features_for_training]\n",
    "y_train = users_train[target_feature] \n",
    "y_test = users_test[target_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a simple decision tree model as first candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(random_state = 0, min_samples_leaf = 30)\n",
    "DT.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jugding by the following confusion matrix the approach is highly improvable, the model is biased and more accuracy is desirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = DT.predict(x_test)\n",
    "plot_confusion_matrix(y_test, pred_test, classes = user_occupations.values(),  normalize=True, size = 12);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
